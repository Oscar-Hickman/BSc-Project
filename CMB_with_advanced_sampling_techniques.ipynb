{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CMB with advanced sampling techniques.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oscar-Hickman/Characterisation-of-photon-BEC-phase-diagram-using-machine-learning/blob/master/CMB_with_advanced_sampling_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYn1pCvCfA81",
        "outputId": "0bb5d2e8-e33f-4c41-fa23-c898725c607e"
      },
      "source": [
        "!pip install -q healpy\n",
        "!pip install camb\n",
        "!pip install corner"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 15.8MB 503kB/s \n",
            "\u001b[?25hCollecting camb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/56/c5f38225869b8b3dc0bd96454bf6087c62a81ec85adf02c441156ee59c73/camb-1.3.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from camb) (1.4.1)\n",
            "Requirement already satisfied: sympy>=1.0 in /usr/local/lib/python3.7/dist-packages (from camb) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=1.0->camb) (1.19.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.0->camb) (1.2.1)\n",
            "Building wheels for collected packages: camb\n",
            "  Building wheel for camb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for camb: filename=camb-1.3.2-cp37-none-any.whl size=1009266 sha256=022d185a9c5e9c842515889a6318ed1cdebef664ef6a08af2a7416ae486cac39\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/a2/8f/5d3c22c8dc8ab613af9be628f6408f4c2817b7ed85d3feb469\n",
            "Successfully built camb\n",
            "Installing collected packages: camb\n",
            "Successfully installed camb-1.3.2\n",
            "Collecting corner\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/ec/9cdcaebd0eb378225312a7952299df201126555cbde1fb2424c63b49d1f4/corner-2.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=2.1 in /usr/local/lib/python3.7/dist-packages (from corner) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1->corner) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1->corner) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1->corner) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1->corner) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1->corner) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1->corner) (1.15.0)\n",
            "Installing collected packages: corner\n",
            "Successfully installed corner-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-uQkISMehRe"
      },
      "source": [
        "#Import Packages\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "#from tensorflow_probability import experimental\n",
        "tfd = tfp.distributions\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import healpy as hp\n",
        "#import pandas as pd\n",
        "import camb \n",
        "from camb import initialpower\n",
        "import glob\n",
        "import pylab as plty\n",
        "from PIL import Image\n",
        "from healpy.sphtfunc import Alm\n",
        "import time \n",
        "import corner\n",
        "#import seaborn as sns\n",
        "import scipy.stats as st\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import os\n",
        "import sys\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_HPFLhqfjYa"
      },
      "source": [
        "#Use CAMB to generate a power spectrum\n",
        "def call_CMB_map(_parameters, _lmax): #lmax above 2551 makes no difference?\n",
        "    '''\n",
        "    parameters = [H0, ombh2, omch2, mnu, omk, tau]  = [Hubble Const, Baryon density, DM density, \n",
        "    Sum 3 neutrino masses/eV, Curvature parameter (Omega kappa), Reionisation optical depth]\n",
        "    '''\n",
        "    if _lmax <= 2551: #can only find power spectrum for lmax <= 2551 since that is the maximum value of the data.\n",
        "        pars = camb.CAMBparams()\n",
        "        pars.set_cosmology(H0 = _parameters[0], ombh2 = _parameters[1], omch2 = _parameters[2], mnu = _parameters[3],\n",
        "                   omk = _parameters[4], tau = _parameters[5])  #Inputs the given cosmological parameters.\n",
        "        pars.InitPower.set_params(As=2e-9, ns=0.965, r=0)\n",
        "        \n",
        "        pars.set_for_lmax(_lmax, lens_potential_accuracy=0) #input the given lmax value\n",
        "        \n",
        "        results = camb.get_results(pars)\n",
        "        powers =results.get_cmb_power_spectra(pars, CMB_unit='muK') #returns the power spectrum in units muK.\n",
        "        \n",
        "        totCL=powers['total'] #returns the total (averaged) power spectrum - including lensed, unlensed power spectra \n",
        "        _DL = totCL[:,0] \n",
        "        \n",
        "        #unlensedCL=powers['unlensed_scalar'] #returns the unlensed scalar power spectrum\n",
        "        #_DL = unlensedCL[:,0] # \n",
        "    \n",
        "        _l = np.arange(len(_DL)) #not sure this CL is actually CL but is actually DL\n",
        "        _CL = []\n",
        "        for i in range(_lmax): #also limits the length of power spectrum to the requested length\n",
        "            if i == 0:\n",
        "                _CL.append(_DL[i]) #since unsure what CL value is for this DL\n",
        "        \n",
        "            else:\n",
        "                _CL.append(_DL[i]/(_l[i]*(_l[i] + 1)))\n",
        "        \n",
        "        _CL = np.array(_CL)    \n",
        "    \n",
        "        return _CL \n",
        "    \n",
        "    else: #prints error if lmax is too large.\n",
        "        print('lmax value is larger than the available data.')\n",
        "        "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXiyr4VSfjMC"
      },
      "source": [
        "#Plots a given power spectrum \n",
        "def plotpwrspctrm(_cls):\n",
        "    _l = np.arange(len(_cls))\n",
        "    plt.plot(_l, _l * (_l + 1) * _cls)\n",
        "    plt.xlabel(\"$\\l$\")\n",
        "    plt.ylabel(\"$\\l(\\l+1)C_{\\l}$\")\n",
        "    plt.grid()\n",
        "    plt.title(\"Power Spectrum\")\n",
        "\n",
        "#PLots a map in the mollview projection \n",
        "def mollviewmap(_map):\n",
        "    hp.mollview(_map, title=\"Map displayed in the Molleview projection\", cmap = None)\n",
        "    hp.graticule()\n",
        "    \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50f7Uf11fyNQ"
      },
      "source": [
        "#Adds random noise to each pixel on a map given a variance \n",
        "def noisemapfunc(_map,_var):\n",
        "    _noisevec = np.random.normal(0,_var,len(_map)) #A vector of the noise applied to each pixel\n",
        "    _newmap = [x + y for x, y in zip(_map, _noisevec)]\n",
        "    _newmap, _noisevec = np.array(_newmap), np.array(_noisevec)\n",
        "    return [_newmap, _noisevec] #returns an array consisiting of [map with added noise, array of the added noise]\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3im-MTgBfwhe"
      },
      "source": [
        "#cls --> something\n",
        "def cltoalm(_cls, _NSIDE, _lmax): #doesn't work (isnt currently being used)\n",
        "    _alms = []\n",
        "    for l in range(_lmax): \n",
        "        if _cls[l] > 0:\n",
        "            _alms.append(np.complex(np.random.normal(0,_cls[l]),0))        #set m=0, which is real\n",
        "        else:\n",
        "            _alms.append(np.complex(0,0))\n",
        "        \n",
        "        for m in range(l+1): #set positive m's\n",
        "            if _cls[l] > 0 and _cls[m] > 0:\n",
        "                _alms.append(np.complex(np.random.normal(0,0.5*_cls[l]),np.random.normal(0,0.5*_cls[m])))\n",
        "            if _cls[l] > 0 and _cls[m] <= 0:\n",
        "                _alms.append(np.complex(np.random.normal(0,0.5*_cls[l]),0))\n",
        "            if _cls[l] <= 0 and _cls[m] > 0:\n",
        "                _alms.append(np.complex(0,np.random.normal(0,0.5*_cls[m])))\n",
        "            else:\n",
        "                _alms.append(np.complex(0,0))\n",
        "    \n",
        "    return _alms   \n",
        "\n",
        "def hpcltoalm(_cls, _NSIDE, _lmax): #Healpy generate alms given cls\n",
        "    return hp.synalm(_cls, _lmax - 1, new = True)\n",
        "\n",
        "def cltomap(_cls, _NSIDE, _lmax): #doesn't work (isnt currently being used)\n",
        "    _alm = cltoalm(_cls, _NSIDE, _lmax)\n",
        "    return almtomap(_alm, _NSIDE, _lmax)\n",
        "\n",
        "def hpcltomap(_cls, _NSIDE, _lmax):   #Healpy generate a map given a power spectrum\n",
        "    return hp.synfast(_cls, _NSIDE, _lmax - 1, new=True) \n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1q7w3lhfxAM"
      },
      "source": [
        "#map --> something\n",
        "def maptocl(_map): #does this manually - doesn't work (isnt currently being used)\n",
        "    return\n",
        "\n",
        "def hpmaptocl(_map, _NSIDE, _lmax): #Generate a power spectrum given cls\n",
        "    return hp.anafast(_map, lmax = _lmax - 1)    #lmax = 3NSIDE by default\n",
        "\n",
        "def maptoalm(_map): #does this manually - doesn't work (isnt currently being used)\n",
        "    _omegp = (4*np.pi)/len(_map)\n",
        "    _lmax = int(np.sqrt(len(_map)*(3/4)))\n",
        "    _NSIDE = int(_lmax/3)\n",
        "    _alm = []\n",
        "    for l in range(_lmax):\n",
        "        for m in range(l+1):\n",
        "            _TpYlm = []\n",
        "            for i in range(len(_map)):\n",
        "                _TpYlm.append(_map[i]*np.conjugate(sphharm(m, l, i, _NSIDE)))\n",
        "                    \n",
        "            _alm.append(_omegp*sum(_TpYlm))\n",
        "    \n",
        "    return np.array(_alm)\n",
        "\n",
        "\n",
        "def hpmaptoalm(_map, _lmax): #Healpy generate alms from map. \n",
        "    return hp.map2alm(_map, _lmax-1)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dKTLtr0fxVV"
      },
      "source": [
        "#alm --> something\n",
        "def almtocl(_alm, lmax): #alm --> cl using alms in my ordering (different to healpys).\n",
        "    _l = np.arange(lmax)\n",
        "    _scaling = 1 / ((2*_l + 1))\n",
        "    count = 0\n",
        "    _new = []\n",
        "    _cl = []\n",
        "    for l in range(lmax):\n",
        "        _new.append([])\n",
        "        for m in range(l):\n",
        "            if m == 0:\n",
        "                _new[l].append(np.absolute(_alm[count])**2)\n",
        "                count = count + 1\n",
        "                \n",
        "            if m > 0:\n",
        "                _new[l].append(2*np.absolute(_alm[count])**2)\n",
        "                count = count + 1\n",
        "              \n",
        "    for i in range(len(_new)):\n",
        "        _cl.append(_scaling[i] * sum(_new[i]))\n",
        "    \n",
        "    return _cl\n",
        "\n",
        "def hpalmtocl(_alms, _lmax): #Healpy estimates the power spectrum from the cls.\n",
        "    return hp.alm2cl(_alms, lmax = _lmax-1)\n",
        "\n",
        "def almtomap(_alm, _NSIDE, _lmax):# alm --> map using alms in my ordering (different to healpys).    #used in psi\n",
        "    _map = []\n",
        "    _Npix = 12*(_NSIDE)**2\n",
        "\n",
        "    for i in range(_Npix):\n",
        "        _sum = []\n",
        "        _count = 0\n",
        "        for l in np.arange(0,_lmax):\n",
        "            for m in np.arange(0,l+1):\n",
        "                if m == 0:\n",
        "                    _sum.append(_alm[_count]*sphharm(m,l,i, _NSIDE))\n",
        "                    _count = _count + 1\n",
        "                else:\n",
        "                    _sum.append(2*(np.real(_alm[_count])*np.real(sphharm(m,l,i, _NSIDE)) -\n",
        "                                   np.imag(_alm[_count])*np.imag(sphharm(m,l,i, _NSIDE))))\n",
        "                    _count = _count + 1\n",
        "        _map.append(sum(_sum))\n",
        "\n",
        "    return np.real(_map)\n",
        "        \n",
        "\n",
        "def almtomap_tf(_alm,_NSIDE, _lmax, _sph):  #used in psitf\n",
        "    _ones = np.ones(len(_alm), dtype = np.complex128)\n",
        "    _count = 0\n",
        "    for l in range(_lmax):\n",
        "        for m in range(l+1):     \n",
        "            if m == 0:\n",
        "                _ones[_count] = np.complex(0.5,0)\n",
        "            _count = _count + 1\n",
        "    _ones = tf.convert_to_tensor(_ones)  \n",
        "    _alm = _ones*_alm\n",
        "    _ralm = tf.math.real(_alm) \n",
        "    _ialm = tf.math.imag(_alm) \n",
        "    _rsph = tf.math.real(_sph) \n",
        "    _isph = tf.math.imag(_sph) \n",
        "\n",
        "    _map1 = tf.linalg.matvec(_rsph,_ralm)\n",
        "    _map2 = tf.linalg.matvec(_isph,_ialm)\n",
        "    _map = 2*(_map1 - _map2)\n",
        "    return _map\n",
        "\n",
        "def almtomap_psi_tf(_alm,_NSIDE, _lmax, _sph_nophi):  #used in psitf\n",
        "    NPIX = 12*(_NSIDE)**2\n",
        "    _ones = np.ones(len(_alm), dtype = np.complex128)\n",
        "    _count = 0\n",
        "    for l in range(_lmax):\n",
        "        for m in range(l+1):     \n",
        "            if m == 0:\n",
        "                _ones[_count] = np.complex(0.5,0)\n",
        "            _count = _count + 1\n",
        "    _ms = []\n",
        "    for l in range(_lmax):\n",
        "        for m in range(l+1):\n",
        "            _ms.append(m)\n",
        "    _ones = tf.convert_to_tensor(_ones)  \n",
        "    _alm = _ones*_alm\n",
        "    _ralm = tf.math.real(_alm) \n",
        "    _ialm = tf.math.imag(_alm) \n",
        "    _thetas1, _phis = hp.pix2ang(nside=_NSIDE, ipix=np.arange(NPIX))\n",
        "    _thetas = []\n",
        "    for i in range(len(_thetas1)):\n",
        "        if _thetas1[i] != np.append(_thetas1,0)[i+1]:\n",
        "            _thetas.append(_thetas1[i])\n",
        "    shaper = []\n",
        "    np_thetas1 = np.array(_thetas1)\n",
        "    for i in range(len(_thetas)):\n",
        "        shaper.append(np.count_nonzero(np_thetas1 == _thetas[i]))\n",
        "    _map = []\n",
        "    count = -1\n",
        "    count2 = -1\n",
        "    for i in range(len(shaper)):\n",
        "        count = count + 1\n",
        "        for j in range(shaper[i]):\n",
        "            term = tf.math.real(_sph_nophi[count])\n",
        "            count2 = count2 + 1\n",
        "            _phisterm = tf.ones(len(_ms), np.float64)*_phis[count2]\n",
        "            _sphterm = tf.complex(term*tf.math.cos(tf.constant(_ms*_phisterm, dtype=np.float64)),term*tf.math.sin(tf.constant(_ms*_phisterm, dtype=np.float64)))\n",
        "            _rsph = tf.math.real(_sphterm) \n",
        "            _isph = tf.math.imag(_sphterm) \n",
        "            _map1 = tf.math.reduce_sum(_rsph*_ralm)\n",
        "            _map2 = tf.math.reduce_sum(_isph*_ialm)\n",
        "            _map.append(2*(_map1 - _map2))\n",
        "    _map = tf.reshape(_map, [NPIX])\n",
        "    return _map\n",
        "\n",
        "\n",
        "\n",
        "def hpalmtomap(_alms, _NSIDE, _lmax):\n",
        "    return hp.alm2map(_alms, _NSIDE ,_lmax-1)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHhSe_m6fxjb"
      },
      "source": [
        "#healpy smoothing for the map and the alms\n",
        "def hpmapsmooth(_map, _lmax): #smooths a given map with a gaussian beam smoother.\n",
        "    return _map #hp.smoothing(_map, lmax = _lmax)\n",
        "\n",
        "def hpalmsmooth(_alms): #smooths a given set of alms with a gaussian beam smoother.\n",
        "    return hp.smoothalm(_alms, fwhm = 0.0)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbCdRjIafx3e"
      },
      "source": [
        "#splits/rejoins the alms into real/imaginary parts so that they can be optimised with scipy.optimize.minimize()\n",
        "def singulartosplitalm(_alm):\n",
        "    _realalm, _imagalm = _alm.real, _alm.imag\n",
        "    return [_realalm, _imagalm]\n",
        "    \n",
        "\n",
        "def splittosingularalm(_realalm, _imagalm, lmax):\n",
        "    _alm = []\n",
        "    _ralmcount = 0\n",
        "    _ialmcount = 0\n",
        "    for l in range(lmax):\n",
        "        for m in range(l+1):\n",
        "            if l == 0 or l == 1:\n",
        "                _alm.append(complex(0,0))\n",
        "            else:  \n",
        "                if m == 0 or m == 1:\n",
        "                    _alm.append(complex(_realalm[_ralmcount], 0))\n",
        "                    _ralmcount = _ralmcount + 1\n",
        "                else:\n",
        "                    _alm.append(complex(_realalm[_ralmcount], _imagalm[_ialmcount]))\n",
        "                    _ralmcount = _ralmcount + 1\n",
        "                    _ialmcount = _ialmcount + 1\n",
        "          \n",
        "    return _alm\n",
        "\n",
        "\n",
        "def splittosingularalm_tf(_realalm, _imagalm, lmax): #takes the real and imaginary parts of the alms and creates a tensor\n",
        "    _zero = tf.zeros(1, dtype = np.float64)\n",
        "    _count = 0\n",
        "    for i in range(3):\n",
        "        _realalm = tf.concat([_zero,_realalm], axis = 0)\n",
        "    for l in range(lmax): #pads zeros to to lmax = 0 values \n",
        "        for m in range(l + 1):\n",
        "            if m == 0 or m == 1: \n",
        "                if l == 0:\n",
        "                    _imagalm = tf.concat([_zero,_imagalm], axis = 0)\n",
        "                else:\n",
        "                    _front = _imagalm[:_count]\n",
        "                    _back = _imagalm[_count:]\n",
        "                    _term = tf.concat([_zero, _back] , axis = 0)\n",
        "                    _imagalm = tf.concat([_front, _term], axis = 0)\n",
        "            _count = _count + 1\n",
        "    return tf.complex(_realalm,_imagalm)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl4Adx77fyB9"
      },
      "source": [
        "#Retrieves the spherical harmonics for a given, l, m and pixel number\n",
        "def sphharm(m, l, _pixno, _NSIDE):\n",
        "    _theta, _phi = hp.pix2ang(nside=_NSIDE, ipix=_pixno)\n",
        "    return sp.special.sph_harm(m, l, _phi, _theta)\n",
        "    \n",
        "    "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSJjpeZ-goqN"
      },
      "source": [
        "#Changes the ordering of the alms from healpy to mine or vice versa\n",
        "def almmotho(_moalm, _lmax):\n",
        "    '''changing the alm ordering from my ordering to healpys'''\n",
        "    _hoalm = []\n",
        "    _count4 = []\n",
        "    _count5 = 0\n",
        "    for i in np.arange(2,_lmax+2):\n",
        "        _count4.append(_count5)\n",
        "        _count5=_count5+i\n",
        "    for i in range(_lmax):\n",
        "        _count1 = 0 \n",
        "        for j in np.arange(i+1,_lmax+1):\n",
        "            _hoalm.append(_moalm[_count1+_count4[i]])\n",
        "            _count1 = _count1 + j\n",
        "    return np.array(_hoalm)\n",
        "\n",
        "\n",
        "def almhotmo(_hoalm, _lmax):\n",
        "    '''changing the alm ordering from healpys ordering to mine'''\n",
        "    _moalm = np.zeros(sum(np.arange(_lmax+1)), dtype = complex)\n",
        "    _count4 = []\n",
        "    _count5 = 0\n",
        "    for i in np.arange(2,_lmax+2):\n",
        "        _count4.append(_count5)\n",
        "        _count5 = _count5+i\n",
        "    _count1 = 0\n",
        "    for i in range(_lmax):\n",
        "        _count2 = 0    \n",
        "        for j in np.arange(i+1,_lmax+1):\n",
        "            _moalm[_count2 + _count4[i]] = _hoalm[_count1]\n",
        "            _count1 = _count1 + 1\n",
        "            _count2 = _count2 + j        \n",
        "    return np.array(_moalm)\n",
        "\n",
        "\n",
        "def alminit(_alms, _lmax):\n",
        "    #pads zeros to the real l=0 and l=1 terms of the alms - in my ordering \n",
        "    _count = 0\n",
        "    for l in range(_lmax):\n",
        "        for m in range(l + 1):\n",
        "            if l == 0 or l == 1:\n",
        "                _alms[_count] = complex(0,0)\n",
        "                _count = _count + 1\n",
        "    _count = 0\n",
        "    for l in range(_lmax):\n",
        "        for m in range(l + 1):\n",
        "            if m == 0 or m == 1:\n",
        "                _alms[_count] = complex(np.real(_alms[_count]),0)\n",
        "                _count = _count + 1\n",
        "            else:\n",
        "                _count = _count + 1\n",
        "    return _alms\n",
        "\n",
        "\n",
        "def hpalminit(_alms, _lmax):\n",
        "    #pads zeros to the real l=0 and l=1 terms of the alms - in healpys ordering \n",
        "    _count = 0\n",
        "    for l in range(_lmax):\n",
        "        for m in range(l + 1):\n",
        "            _count = _count + 1\n",
        "            if _count == 1 or _count == 2 or _count == _lmax+1:\n",
        "                _alms[_count - 1] = complex(0,0)\n",
        "    _count = 0\n",
        "    for l in range(2*_lmax - 1):\n",
        "        _alms[_count] = complex(np.real(_alms[_count]),0)\n",
        "        _count = _count + 1\n",
        "    return _alms\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAhlZVTdgpox"
      },
      "source": [
        "def multtensor(_lmax,_lenalm):\n",
        "    _shape = np.zeros([_lmax,_lenalm]) #matrix for the calculation of the psi in psi_tf\n",
        "    _count = 0\n",
        "    for i in range(_lmax):\n",
        "        for j in np.arange(0,i+1):\n",
        "            if j == 0:\n",
        "                _shape[i][_count] = 1.0\n",
        "                _count = _count + 1\n",
        "            else:\n",
        "                _shape[i][_count] = 2.0\n",
        "                _count = _count + 1\n",
        "    return tf.convert_to_tensor(_shape, dtype = np.float64)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCRNcEv8Bvzx"
      },
      "source": [
        "#Run the normal hmc sampler\n",
        "def run_chain_hmc(modelparams, initial_state, _step_size = 0.01, num_results = 1000, num_burnin_steps=0, _n_lfs = 1): \n",
        "    '''Returns the desired walks through parameter space for a fixed step size.'''\n",
        "    hmc_kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn=modelparams.psi_tf, step_size=_step_size,\n",
        "                                                num_leapfrog_steps=_n_lfs)\n",
        "    return tfp.mcmc.sample_chain(num_results=num_results, num_burnin_steps=num_burnin_steps, \n",
        "                               current_state=initial_state, kernel=hmc_kernel, trace_fn=lambda current_state,\n",
        "                               kernel_results: kernel_results)\n",
        "\n",
        "#Run the variable step size hmc\n",
        "def run_chain_vhmc(modelparams, initial_state, _step_size = 0.01, trgt_acc_prob = 0.75, num_results = 1000, num_burnin_steps=0, _n_lfs = 1):\n",
        "    kernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob_fn=modelparams.psi_tf,num_leapfrog_steps=2,\n",
        "    step_size=_step_size)\n",
        "    vhmc_kernel = tfp.mcmc.SimpleStepSizeAdaptation(inner_kernel=kernel,target_accept_prob = trgt_acc_prob,\n",
        "                                                    num_adaptation_steps=int(num_burnin_steps * 0.8))\n",
        "    \n",
        "    return tfp.mcmc.sample_chain(num_results=num_results, num_burnin_steps=num_burnin_steps, \n",
        "                               current_state=initial_state, kernel=vhmc_kernel, trace_fn=lambda current_state,\n",
        "                               kernel_results: kernel_results)\n",
        "\n",
        "#Run the nut sampler chain\n",
        "def run_chain_nut(modelparams, initial_state, _step_size = 0.01, num_results=1000, num_burnin_steps=0, mtd = 10, med = 1000, u_lfs = 1, pi = 10): \n",
        "    '''Returns the desired walks through parameter space for a fixed step size.'''\n",
        "    nut_kernel = tfp.mcmc.NoUTurnSampler(target_log_prob_fn=modelparams.psi_tf, step_size=_step_size,\n",
        "                                         max_tree_depth=mtd, max_energy_diff=med,\n",
        "                                         unrolled_leapfrog_steps=u_lfs, parallel_iterations=pi)\n",
        "    return tfp.mcmc.sample_chain(num_results=num_results, num_burnin_steps=num_burnin_steps, \n",
        "                               current_state=initial_state, kernel=nut_kernel, trace_fn=lambda current_state,\n",
        "                               kernel_results: kernel_results)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hc6w9W-gplr"
      },
      "source": [
        "class CMB_Advanced_Sampling:\n",
        "    '''\n",
        "    '''\n",
        "    def __init__(self, _lmax, _NSIDE, _noisesig):\n",
        "        '''\n",
        "        '''\n",
        "        lcdm_parameters = np.array([67.74, 0.0486, 0.2589, 0.06, 0.0, 0.066]) #parameters for the ΛCDM model\n",
        "        \n",
        "        NPIX = 12*(_NSIDE**2)\n",
        "        n = np.linspace(_noisesig,_noisesig,NPIX) #Array of stds for all the pixels\n",
        "        Ninv = []\n",
        "        for i in range(NPIX):\n",
        "            Ninv.append(1/(n[i]**2)) #finds the inverse noise matrix\n",
        "        lcdm_cls = call_CMB_map(lcdm_parameters, _lmax) #power spectrum for the given parameters and lmax.\n",
        "        notpad_lcdm_alms = hpcltoalm(lcdm_cls, _NSIDE, _lmax)\n",
        "        pad_lcdm_alms = hpalminit(notpad_lcdm_alms, _lmax)\n",
        "        pad_lcdm_map = hpalmtomap(pad_lcdm_alms, _NSIDE, _lmax)  #generates a map from the power spectrum\n",
        "        pad_lcdm_map = hpmapsmooth(pad_lcdm_map, _NSIDE) #applies a gaussian beam smoother to the map\n",
        "        notpad_prior_map = noisemapfunc(pad_lcdm_map,n[0])[0] #adds noise to the map\n",
        "        notpad_prior_halms = hpmaptoalm(notpad_prior_map, _lmax) #noisey alms in my  healpys ordering\n",
        "        pad_prior_halms = hpalminit(notpad_prior_halms,_lmax)\n",
        "        pad_prior_map = hpalmtomap(pad_prior_halms, _NSIDE, _lmax)\n",
        "        pad_prior_alms = almhotmo(pad_prior_halms, _lmax) #noisy alms in my ordering \n",
        "        pad_prior_cls = hpalmtocl(pad_prior_halms, _lmax) #noisy power spectrum\n",
        "   \n",
        "        _sph = []\n",
        "        _ls = []\n",
        "        _ms = []\n",
        "        for l in range(_lmax):\n",
        "            for m in range(l+1):\n",
        "                _ls.append(l)\n",
        "                _ms.append(m)\n",
        "        _thetas, _phis = hp.pix2ang(nside=_NSIDE, ipix=np.arange(NPIX))\n",
        "        #for i in range(NPIX):\n",
        "        #    _sph.append(sp.special.sph_harm(_ms,_ls,_phis[i], _thetas[i]))\n",
        "        #_sph = tf.convert_to_tensor(_sph, dtype = np.complex128)\n",
        "\n",
        "        _sph1 = []\n",
        "        _thetas1, _phis = hp.pix2ang(nside=_NSIDE, ipix=np.arange(NPIX))\n",
        "        _thetas = []\n",
        "        for i in range(len(_thetas1)):\n",
        "            if _thetas1[i] != np.append(_thetas1,0)[i+1]:\n",
        "                _thetas.append(_thetas1[i])\n",
        "        for i in range(len(_thetas)):\n",
        "            _sph1.append(list(np.real(sp.special.sph_harm(_ms,_ls,0, _thetas[i]))))\n",
        "\n",
        "        _sph = tf.convert_to_tensor(_sph1, dtype = np.float64)\n",
        "\n",
        "        shape = multtensor(_lmax,int(_lmax*(_lmax + 1)/2)) #A tensor for the spherical harmonics in the maptoalm_tf function\n",
        "        r_alms_init = pad_prior_alms.real\n",
        "        i_alms_init = pad_prior_alms.imag\n",
        "        x0 = []\n",
        "        _count = 0\n",
        "        for i in range(_lmax - 2):\n",
        "            if pad_prior_cls[i+2] > 0:\n",
        "                x0.append(np.log(pad_prior_cls[i+2]))\n",
        "            else:\n",
        "                x0.append(0)\n",
        "        _count = 0\n",
        "        for l in range(_lmax):\n",
        "            for m in range(l + 1):\n",
        "                if l == 0 or l == 1:\n",
        "                    _count = _count + 1\n",
        "                else:\n",
        "                    x0.append(r_alms_init[_count])\n",
        "                    _count = _count + 1\n",
        "        _count = 0\n",
        "        for l in range(_lmax):\n",
        "            for m in range(l + 1):\n",
        "                if m == 0 or m == 1:\n",
        "                    _count = _count + 1\n",
        "                else:\n",
        "                    x0.append(i_alms_init[_count])\n",
        "                    _count = _count + 1\n",
        "                 \n",
        "        self.lmax = _lmax\n",
        "        self.NSIDE = _NSIDE\n",
        "        self.noisesig = _noisesig\n",
        "        self.Ninv = Ninv\n",
        "        self.NPIX = NPIX\n",
        "        \n",
        "        self.lcdm_cls = lcdm_cls\n",
        "        self.lcdm_alms = pad_lcdm_alms\n",
        "        self.lcdm_map = pad_lcdm_map\n",
        "        self.prior_cls = pad_prior_cls\n",
        "        self.prior_alms = pad_prior_alms\n",
        "        self.prior_map = pad_prior_map\n",
        "    \n",
        "        self.shape = shape\n",
        "        self.sph = _sph\n",
        "        self.x0 = x0\n",
        "       \n",
        "    \n",
        "    def psi(self, _params): #unnormalised log probability\n",
        "        '''\n",
        "        Negative log of the posterior - 'psi'.\n",
        "        '''\n",
        "        _params = self.x0\n",
        "        _lmax = self.lmax\n",
        "        _NSIDE = self.NSIDE\n",
        "        _map = self.prior_map\n",
        "        _Ninv = self.Ninv\n",
        "        _lncl, _realalm, _imagalm = [0,0], [], []\n",
        "        for i in range(_lmax-2):\n",
        "            _lncl.append(_params[i])\n",
        "        for i in range(int(_lmax*(_lmax+1)/2) - 3):\n",
        "            _realalm.append(_params[i + _lmax-2])\n",
        "        for i in range(int(_lmax*(_lmax+1)/2)-(2*_lmax-1)):\n",
        "            _imagalm.append(_params[i + _lmax-2 + int(_lmax*(_lmax+1)/2) - 3])\n",
        "    \n",
        "        _d = _map\n",
        "        _a = splittosingularalm(_realalm, _imagalm, _lmax)\n",
        "        _Ya = hpalmtomap(almmotho(_a,_lmax), _NSIDE, _lmax)\n",
        "        _BYa =  _Ya #mapsmooth(_Ya, _lmax)\n",
        "        \n",
        "        _elem, _psi1 ,_psi2, _psi3 = [], [], [], []\n",
        "        \n",
        "        for i in range(len(_d)):\n",
        "            _elem.append(_d[i] - _BYa[i])\n",
        "            _psi1.append(0.5*(_elem[i]**2)*_Ninv[i]) #first term in the taylor paper \n",
        "        \n",
        "        _l = np.arange(_lmax)\n",
        "        for i in range(len(_lncl)):\n",
        "            _psi2.append((_l[i] + 0.5)*(_lncl[i])) #second term in the taylor paper \n",
        "    \n",
        "        _a = np.absolute(np.array(_a))**2\n",
        "        _as = np.matmul(self.shape.numpy(),_a)\n",
        "        _psi3 = 0.5*_as/np.exp(np.array(_lncl)) #third term in the taylor paper \n",
        "    \n",
        "        _psi = -(sum(_psi1) + sum(_psi2) + sum(_psi3))\n",
        "        print('psi =',-_psi)\n",
        "        return -_psi\n",
        "    \n",
        "    \n",
        "    def psi_tf(self,_params):\n",
        "        '''\n",
        "        #negative log of the posterior - psi, in Tensorflow.\n",
        "        '''\n",
        "        _map, _lmax, _NSIDE, _Ninv = self.prior_map, self.lmax, self.NSIDE, self.Ninv\n",
        "        _lnclstart = tf.zeros(2, np.float64)\n",
        "        _lncl = tf.concat([_lnclstart,_params[:(_lmax - 2)]], axis = 0)\n",
        "        _realalm = _params[_lmax - 2:(int(_lmax*(_lmax+1)/2) - 3 + _lmax - 2)]\n",
        "        _imagalm = _params[(int(_lmax*(_lmax+1)/2) - 3 + _lmax - 2):]\n",
        "        \n",
        "        _d = _map\n",
        "        _a = splittosingularalm_tf(_realalm, _imagalm, _lmax)\n",
        "        _Ya = almtomap_psi_tf(_a, _NSIDE, _lmax, self.sph)\n",
        "        _BYa =  _Ya #mapsmooth(_Ya, _lmax)\n",
        "        #print('a',_a)\n",
        "        _elem = _d - _BYa\n",
        "        _psi1 = 0.5*(_elem**2)*_Ninv #first term in the taylor paper \n",
        "        #print('d',_d)\n",
        "        #print('Bya',_BYa)\n",
        "        #print('abdif', abs(_d - _BYa))\n",
        "        _l = tf.range(_lmax, dtype = np.float64)\n",
        "        _psi2 = (_l+0.5)*_lncl #second term in the taylor paper \n",
        "        \n",
        "        _a = tf.math.abs(_a)**2\n",
        "        _as = tf.linalg.matvec(self.shape,_a)\n",
        "        _psi3 = 0.5*_as/tf.math.exp(_lncl) #third term in the taylor paper \n",
        "            \n",
        "        _psi = tf.reduce_sum(_psi1) + tf.reduce_sum(_psi2) + tf.reduce_sum(_psi3) \n",
        "        #print('psi =',_psi.numpy())   \n",
        "        #print('psi1 =',tf.reduce_sum(_psi1),'psi2 =',tf.reduce_sum(_psi2),'psi3 =',tf.reduce_sum(_psi3))\n",
        "        \n",
        "        self.__psi_record1.append(-tf.reduce_sum(_psi1).numpy())\n",
        "        self.__psi_record2.append(-tf.reduce_sum(_psi2).numpy())\n",
        "        self.__psi_record3.append(-tf.reduce_sum(_psi3).numpy())\n",
        "        self.__psi_record.append(-_psi.numpy())\n",
        "        #print('psi1',tf.reduce_sum(_psi1),'psi2',tf.reduce_sum(_psi2),'psi3',tf.reduce_sum(_psi3))\n",
        "        #print(-_psi)\n",
        "        return -_psi\n",
        "    \n",
        "    def lcdm_cls(self): #return the alms from the lambda cdm model\n",
        "        return self.lcdm_cls\n",
        "    def lcdm_alms(self): #return the alms from the lambda cdm model\n",
        "        return self.lcdm_alms\n",
        "    def lcdm_map(self):\n",
        "        return self.lcdm_map\n",
        "    def prior_cls(self):\n",
        "        return self.prior_cls\n",
        "    def prior_alms(self): #return the prior alms\n",
        "        return self.prior_alms\n",
        "    def prior_map(self):\n",
        "        return self.prior_map\n",
        "    def prior_parameters_tf(self): #return the prior for the log posterior\n",
        "        return tf.convert_to_tensor(self.x0)\n",
        "    \n",
        "    def psisrecordinit(self):\n",
        "        self.__psi_record = []\n",
        "        self.__psi_record1 = []\n",
        "        self.__psi_record2 = []\n",
        "        self.__psi_record3 = []\n",
        "       \n",
        "    def psisrecordreturn(self):\n",
        "        return[self.__psi_record,self.__psi_record1,self.__psi_record2,self.__psi_record3]\n",
        "    \n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-GHXp-bRiH8"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}